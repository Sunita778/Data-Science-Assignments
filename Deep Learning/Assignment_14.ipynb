{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d644769f",
   "metadata": {},
   "source": [
    "## Submitted by : `Sunita Pradhan`\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649016d",
   "metadata": {},
   "source": [
    "### 1. Is it okay to initialize all the weights to the same value as long as that value is selected randomly using He initialization?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b0fde8",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "Initializing all weights to the same value, even if randomly selected using He initialization, is not recommended. The purpose of random initialization is to break the symmetry between neurons and prevent them from learning the same features. If all weights are set to the same value, the neurons will still be symmetric, and the network will not be able to effectively learn diverse representations. Therefore, it is essential to initialize the weights with random values, following a proper initialization method like He initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6903b",
   "metadata": {},
   "source": [
    "### 2. Is it okay to initialize the bias terms to 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a698d40",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "It is generally acceptable to initialize the bias terms to 0. Bias terms provide an additional parameter that allows the model to shift the activation function's output. Initializing biases to 0 initially means that the network starts with a neutral bias, and during training, the biases will be adjusted based on the data. However, in certain cases, such as recurrent neural networks (RNNs), initializing biases to non-zero values can be beneficial to help the network learn more quickly. Overall, initializing biases to 0 is a common and reasonable practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b837d",
   "metadata": {},
   "source": [
    "### 3. Name three advantages of the ELU activation function over ReLU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db370d",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "Three advantages of the ELU activation function over ReLU are:\n",
    "\n",
    "a) ELU can handle negative values better than ReLU. It allows the activation to have negative values, which helps prevent the problem of \"dying ReLU\" where neurons can get stuck and not activate. ELU's exponential decay for negative inputs enables the gradients to flow even for negative values.\n",
    "\n",
    "b) ELU has a smoother transition around zero compared to ReLU. This smoothness can help the model learn more gradually and avoid abrupt changes in the activation, which can be beneficial for training stability.\n",
    "\n",
    "c) ELU has been observed to improve training performance and achieve higher accuracy compared to ReLU, particularly on certain types of data or in deeper networks. It helps mitigate the vanishing gradient problem and can lead to faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aacf8b5",
   "metadata": {},
   "source": [
    "### 4. In which cases would you want to use each of the following activation functions: ELU, leaky ReLU (and its variants), ReLU, tanh, logistic, and softmax?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6383312",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "The choice of activation functions depends on the specific problem and network architecture. Here are some common cases where each activation function may be preferred:\n",
    "\n",
    "- ELU: ELU is generally a good choice as it combines the advantages of ReLU and provides better handling of negative values. It is beneficial for deep networks and can help prevent the dying ReLU problem.\n",
    "- Leaky ReLU (and variants): Leaky ReLU is suitable when you want to introduce a small slope for negative inputs to prevent the dying ReLU problem. It is a good alternative to ReLU and can be effective in preventing dead neurons.\n",
    "- ReLU: ReLU is widely used as it is computationally efficient and provides good performance in many cases. It is a good choice for most applications, especially when dealing with shallow networks or situations where interpretability and sparsity are desired.\n",
    "- Tanh: Tanh is useful in cases where the output needs to be scaled between -1 and 1. It can be used in both shallow and deep networks, although it may suffer from the vanishing gradient problem for deep architectures.\n",
    "- Logistic (Sigmoid): Logistic activation is commonly used in binary classification problems where the output needs to be within the range of 0 and 1. It is not recommended for deep networks due to the vanishing gradient problem.\n",
    "- Softmax: Softmax is primarily used in multi-class classification tasks where the outputs need to represent probability distributions over multiple classes. It ensures that the sum of the probabilities adds up to 1, allowing the network to make class predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9d1f5",
   "metadata": {},
   "source": [
    "### 5. What may happen if you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using a MomentumOptimizer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cddb1f",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "Setting the momentum hyperparameter too close to 1 (e.g., 0.99999) in MomentumOptimizer can lead to unstable training. Momentum is a technique used to accelerate gradient descent by accumulating a fraction of past gradients to determine the direction of the update. When the momentum value is close to 1, it means that the contribution of past gradients becomes extremely dominant. This can cause the optimizer to overshoot the minimum, leading to oscillations or instability in the training process. It may prevent the optimizer from converging to the optimal solution or slow down the convergence process due to excessive momentum. It is generally recommended to use values for momentum closer to 0.9 for most practical cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1800c6a5",
   "metadata": {},
   "source": [
    "### 6. Name three ways you can produce a sparse model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e262b",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "Three ways to produce a sparse model are:\n",
    "\n",
    "a) L1 regularization: Applying L1 regularization to the model's weights encourages sparsity by adding a penalty term proportional to the absolute values of the weights. As a result, the optimizer tends to drive many weights to exactly zero, effectively creating a sparse model.\n",
    "\n",
    "b) Dropout: Dropout, while primarily used for regularization, can also produce a sparse model. During training, dropout randomly sets a fraction of the neurons to zero, effectively removing their contributions to the network's activations and weights. This sparsity induced by dropout can carry over to the inference phase.\n",
    "\n",
    "c) Pruning: Pruning involves iteratively removing or setting small-weighted connections to zero based on certain criteria. By pruning connections with low weights, the model becomes sparser. Techniques like magnitude-based pruning or iterative pruning can be used to prune weights or entire neurons based on their importance or contribution to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16ab36",
   "metadata": {},
   "source": [
    "### 7. Does dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5173de1",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "Dropout can slightly slow down training since it introduces randomness and requires training the model with multiple forward and backward passes for each mini-batch. The additional computations involved in dropout can increase the training time. However, the regularization benefits of dropout often outweigh this minor increase in training time by preventing overfitting and improving the model's generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ec6e9",
   "metadata": {},
   "source": [
    "### Thank youðŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
